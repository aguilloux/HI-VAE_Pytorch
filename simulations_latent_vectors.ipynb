{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43788ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hivae/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n",
      "Device : cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tableone import TableOne\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "from utils import data_processing, visualization\n",
    "from utils.simulations import *\n",
    "from execute import surv_hivae, surv_gan, surv_vae\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "from utils.metrics import fit_cox_model, general_metrics\n",
    "\n",
    "from synthcity.utils.constants import DEVICE\n",
    "print('Device :', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e339ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_dirs(dataset_name):\n",
    "    base_path = os.path.join(\"./dataset\", dataset_name)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_path, \"optuna_results\"), exist_ok=True)\n",
    "    return base_path\n",
    "\n",
    "def adjust_feat_types_for_generator(generator_name, feat_types_dict):\n",
    "    feat_types_dict_ext = [dict(ft) for ft in feat_types_dict]  # deep copy\n",
    "    for d in feat_types_dict_ext:\n",
    "        if d['name'] == \"survcens\":\n",
    "            if generator_name == \"HI-VAE_weibull\" or generator_name == \"HI-VAE_weibull_prior\":\n",
    "                d[\"type\"] = 'surv_weibull'\n",
    "            elif generator_name == \"HI-VAE_lognormal\":\n",
    "                d[\"type\"] = 'surv'\n",
    "            else:\n",
    "                d[\"type\"] = 'surv_piecewise'\n",
    "    return feat_types_dict_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cdffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Simulation parameters\n",
    "n_samples = 600\n",
    "n_features_bytype = 6\n",
    "n_active_features = 3 \n",
    "treatment_effect = 0.\n",
    "p_treated = 0.5\n",
    "shape_T = 2.\n",
    "shape_C = 2.\n",
    "scale_C = 2.5\n",
    "scale_C_indep = 3.9\n",
    "feature_types_list = [\"real\", \"cat\"]\n",
    "independent = True\n",
    "data_types_create = True\n",
    "\n",
    "\n",
    "metric_optuna = \"survival_km_distance\"\n",
    "dataset_name = \"Simulations_6_indep\"\n",
    "base_path = prepare_dataset_dirs(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96570427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators_sel = [\"HI-VAE_weibull\", \"HI-VAE_piecewise\", \"Surv-GAN\", \"Surv-VAE\", \"HI-VAE_weibull_prior\", \"HI-VAE_piecewise_prior\"]\n",
    "generators_sel = [\"HI-VAE_weibull\", \"HI-VAE_piecewise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccde8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators_dict = {\"HI-VAE_weibull\" : surv_hivae,\n",
    "                    \"HI-VAE_piecewise\" : surv_hivae,\n",
    "                    \"HI-VAE_lognormal\" : surv_hivae,\n",
    "                    \"Surv-GAN\" : surv_gan,\n",
    "                    \"Surv-VAE\" : surv_vae, \n",
    "                    \"HI-VAE_weibull_prior\" : surv_hivae, \n",
    "                    \"HI-VAE_piecewise_prior\" : surv_hivae}\n",
    "\n",
    "# BEST PARAMETERS\n",
    "best_params_dict = {}\n",
    "name_config = \"simu_N{}_nfeat{}_t{}\".format(n_samples, n_features_bytype, int(treatment_effect))\n",
    "n_trials = 150\n",
    "for generator_name in generators_sel:\n",
    "    best_params_file = os.path.join(base_path, \"optuna_results\", \"best_params_{}_ntrials{}_{}_{}.json\".format(name_config, n_trials, metric_optuna, generator_name))\n",
    "    with open(best_params_file, \"r\") as f:\n",
    "        best_params_dict[generator_name] = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc31fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_generated_dataset = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96804fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0]  time: 0.0951, ELBO_train: -15.98717213, KL_z: 2.46765232, KL_s: 0.10257244, reconstruction loss: -13.41694736\n",
      "Epoch: [100]  time: 0.8532, ELBO_train: -12.11521721, KL_z: 1.24780822, KL_s: 0.03155565, reconstruction loss: -10.83585334\n",
      "Epoch: [200]  time: 1.5961, ELBO_train: -11.68682480, KL_z: 1.32029927, KL_s: 0.01734877, reconstruction loss: -10.34917676\n",
      "Epoch: [300]  time: 2.2977, ELBO_train: -11.76412106, KL_z: 1.42126477, KL_s: 0.01514816, reconstruction loss: -10.32770813\n",
      "Epoch: [400]  time: 2.9871, ELBO_train: -11.64529896, KL_z: 1.40081096, KL_s: 0.01474285, reconstruction loss: -10.22974515\n",
      "Epoch: [500]  time: 3.6842, ELBO_train: -11.63064003, KL_z: 1.52212512, KL_s: 0.01466656, reconstruction loss: -10.09384835\n",
      "Epoch: [600]  time: 4.3826, ELBO_train: -11.55868340, KL_z: 1.56701541, KL_s: 0.01482153, reconstruction loss: -9.97684646\n",
      "Epoch: [700]  time: 5.0742, ELBO_train: -11.33791542, KL_z: 1.62374008, KL_s: 0.01600027, reconstruction loss: -9.69817507\n",
      "Epoch: [800]  time: 5.7586, ELBO_train: -11.67842293, KL_z: 1.69686770, KL_s: 0.01516533, reconstruction loss: -9.96638989\n",
      "Early stopping at epoch 800.\n",
      "Training finished.\n",
      "Epoch: [ 0]  time: 0.0107, ELBO_train: -14.65927982, KL_z: 1.21138132, KL_s: 0.09823322, reconstruction loss: -13.34966528\n",
      "Epoch: [100]  time: 0.8816, ELBO_train: -12.15475559, KL_z: 1.13852370, KL_s: 0.02726889, reconstruction loss: -10.98896301\n",
      "Epoch: [200]  time: 1.7161, ELBO_train: -11.95031643, KL_z: 1.37200272, KL_s: 0.01346827, reconstruction loss: -10.56484544\n",
      "Epoch: [300]  time: 2.5579, ELBO_train: -11.96893406, KL_z: 1.44174564, KL_s: 0.01090956, reconstruction loss: -10.51627886\n",
      "Epoch: [400]  time: 3.4038, ELBO_train: -11.68778324, KL_z: 1.45819926, KL_s: 0.01011801, reconstruction loss: -10.21946597\n",
      "Epoch: [500]  time: 4.2280, ELBO_train: -11.40904427, KL_z: 1.60423148, KL_s: 0.00988817, reconstruction loss: -9.79492462\n",
      "Epoch: [600]  time: 5.0755, ELBO_train: -11.55938053, KL_z: 1.72874486, KL_s: 0.01021671, reconstruction loss: -9.82041895\n",
      "Epoch: [700]  time: 5.9099, ELBO_train: -11.26403809, KL_z: 1.86265242, KL_s: 0.01012802, reconstruction loss: -9.39125764\n",
      "Epoch: [800]  time: 6.7381, ELBO_train: -11.17293358, KL_z: 1.99124992, KL_s: 0.01018190, reconstruction loss: -9.17150176\n",
      "Epoch: [900]  time: 7.5616, ELBO_train: -11.19031334, KL_z: 1.99338078, KL_s: 0.01056433, reconstruction loss: -9.18636823\n",
      "Epoch: [1000]  time: 8.3940, ELBO_train: -11.21244335, KL_z: 2.02870560, KL_s: 0.01068163, reconstruction loss: -9.17305613\n",
      "Epoch: [1100]  time: 9.2248, ELBO_train: -11.18966961, KL_z: 2.05626750, KL_s: 0.01090765, reconstruction loss: -9.12249446\n",
      "Epoch: [1200]  time: 10.0845, ELBO_train: -11.21801853, KL_z: 2.10239387, KL_s: 0.01130009, reconstruction loss: -9.10432458\n",
      "Early stopping at epoch 1200.\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "control, treated, types = simulation(treatment_effect, n_samples, independent, feature_types_list,\n",
    "                                       n_features_bytype, n_active_features, p_treated, shape_T,\n",
    "                                       shape_C, scale_C, scale_C_indep, data_types_create, seed=0)\n",
    "control = control.drop(columns='treatment')\n",
    "\n",
    "data_file_control = os.path.join(f\"./dataset/{dataset_name}\", \"data_control.csv\")\n",
    "feat_types_file_control = os.path.join(f\"./dataset/{dataset_name}\", \"data_types_control.csv\")\n",
    "control.to_csv(data_file_control, index=False, header=False)\n",
    "types.to_csv(feat_types_file_control, index=False)\n",
    "\n",
    "# Load and process control data\n",
    "df_init_control_encoded, feat_types_dict, miss_mask_control, true_miss_mask_control, _ = data_processing.read_data(\n",
    "        data_file_control, feat_types_file_control, miss_file=\"Missing.csv\", true_miss_file=None)\n",
    "data_init_control_encoded = torch.from_numpy(df_init_control_encoded.values)\n",
    "data_init_control = data_processing.discrete_variables_transformation(data_init_control_encoded, feat_types_dict)\n",
    "\n",
    "# Format control data into DataFrame\n",
    "fnames = types['name'][:-1].tolist() + [\"time\", \"censor\"]\n",
    "df_init_control = pd.DataFrame(data_init_control.numpy(), columns=fnames)\n",
    "df_init_control[\"treatment\"] = 0\n",
    "\n",
    "df_gen_control_dict ={}\n",
    "# For each generator, perform the data generation with the best params\n",
    "for generator_name in generators_sel:\n",
    "    best_params = best_params_dict[generator_name]\n",
    "    if generator_name in [\"HI-VAE_lognormal\", \"HI-VAE_weibull\", \"HI-VAE_piecewise\", \"HI-VAE_weibull_prior\", \"HI-VAE_piecewise_prior\"]:\n",
    "        if generator_name in [\"HI-VAE_weibull_prior\", \"HI-VAE_piecewise_prior\"]:\n",
    "            gen_from_prior = True\n",
    "        else:\n",
    "            gen_from_prior = False\n",
    "        feat_types_dict_ext = adjust_feat_types_for_generator(generator_name, feat_types_dict)\n",
    "        data_gen_control, s_total, z_total, y_total = generators_dict[generator_name].run(df_init_control_encoded, miss_mask_control, \n",
    "                                                                true_miss_mask_control, feat_types_dict_ext, \n",
    "                                                                n_generated_dataset, params=best_params, epochs=10000, gen_from_prior=gen_from_prior, return_latent_vectors=True)\n",
    "    # else:\n",
    "    #     data_gen_control = generators_dict[generator_name].run(data_init_control, columns=fnames, \n",
    "    #                                                             target_column=\"censor\", time_to_event_column=\"time\", \n",
    "    #                                                             n_generated_dataset=n_generated_dataset, \n",
    "    #                                                             params=best_params)\n",
    "\n",
    "    list_df_gen_control = []\n",
    "    for i in range(n_generated_dataset):\n",
    "        df_gen_control = pd.DataFrame(data_gen_control[i].numpy(), columns=fnames)\n",
    "        df_gen_control[\"treatment\"] = 0\n",
    "        list_df_gen_control.append(df_gen_control)\n",
    "    df_gen_control_dict[generator_name] = list_df_gen_control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "225cf601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 150]) torch.Size([300, 60]) torch.Size([300, 2275])\n"
     ]
    }
   ],
   "source": [
    "print(s_total.shape, z_total.shape, y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35d3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hivae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
