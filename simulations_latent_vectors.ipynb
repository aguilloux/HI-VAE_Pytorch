{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43788ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hivae/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n",
      "Device : cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tableone import TableOne\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "from utils import data_processing, visualization\n",
    "from utils.simulations import *\n",
    "from execute import surv_hivae, surv_gan, surv_vae\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "from utils.metrics import fit_cox_model, general_metrics\n",
    "\n",
    "from synthcity.utils.constants import DEVICE\n",
    "print('Device :', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e339ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_dirs(dataset_name):\n",
    "    base_path = os.path.join(\"./dataset\", dataset_name)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_path, \"optuna_results\"), exist_ok=True)\n",
    "    return base_path\n",
    "\n",
    "def adjust_feat_types_for_generator(generator_name, feat_types_dict):\n",
    "    feat_types_dict_ext = [dict(ft) for ft in feat_types_dict]  # deep copy\n",
    "    for d in feat_types_dict_ext:\n",
    "        if d['name'] == \"survcens\":\n",
    "            if generator_name == \"HI-VAE_weibull\" or generator_name == \"HI-VAE_weibull_prior\":\n",
    "                d[\"type\"] = 'surv_weibull'\n",
    "            elif generator_name == \"HI-VAE_lognormal\":\n",
    "                d[\"type\"] = 'surv'\n",
    "            else:\n",
    "                d[\"type\"] = 'surv_piecewise'\n",
    "    return feat_types_dict_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cdffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Simulation parameters\n",
    "n_samples = 600\n",
    "n_features_bytype = 6\n",
    "n_active_features = 3 \n",
    "treatment_effect = 0.\n",
    "p_treated = 0.5\n",
    "shape_T = 2.\n",
    "shape_C = 2.\n",
    "scale_C = 2.5\n",
    "scale_C_indep = 3.9\n",
    "feature_types_list = [\"real\", \"cat\"]\n",
    "independent = True\n",
    "data_types_create = True\n",
    "\n",
    "\n",
    "metric_optuna = \"survival_km_distance\"\n",
    "dataset_name = \"Simulations_6_indep\"\n",
    "base_path = prepare_dataset_dirs(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96570427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators_sel = [\"HI-VAE_weibull\", \"HI-VAE_piecewise\", \"Surv-GAN\", \"Surv-VAE\", \"HI-VAE_weibull_prior\", \"HI-VAE_piecewise_prior\"]\n",
    "generators_sel = [\"HI-VAE_weibull\", \"HI-VAE_piecewise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccde8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators_dict = {\"HI-VAE_weibull\" : surv_hivae,\n",
    "                    \"HI-VAE_piecewise\" : surv_hivae,\n",
    "                    \"HI-VAE_lognormal\" : surv_hivae,\n",
    "                    \"Surv-GAN\" : surv_gan,\n",
    "                    \"Surv-VAE\" : surv_vae, \n",
    "                    \"HI-VAE_weibull_prior\" : surv_hivae, \n",
    "                    \"HI-VAE_piecewise_prior\" : surv_hivae}\n",
    "\n",
    "# BEST PARAMETERS\n",
    "best_params_dict = {}\n",
    "name_config = \"simu_N{}_nfeat{}_t{}\".format(n_samples, n_features_bytype, int(treatment_effect))\n",
    "n_trials = 150\n",
    "for generator_name in generators_sel:\n",
    "    best_params_file = os.path.join(base_path, \"optuna_results\", \"best_params_{}_ntrials{}_{}_{}.json\".format(name_config, n_trials, metric_optuna, generator_name))\n",
    "    with open(best_params_file, \"r\") as f:\n",
    "        best_params_dict[generator_name] = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc31fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_generated_dataset = 1\n",
    "n_simulated_dataset = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7621a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_control_dict = {generator_name: [] for generator_name in generators_sel}\n",
    "latent_s = {generator_name: [] for generator_name in generators_sel}\n",
    "latent_z = {generator_name: [] for generator_name in generators_sel}\n",
    "latent_y = {generator_name: [] for generator_name in generators_sel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96804fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0]  time: 0.0825, ELBO_train: -15.98717213, KL_z: 2.46765232, KL_s: 0.10257244, reconstruction loss: -13.41694736\n",
      "Epoch: [100]  time: 0.7724, ELBO_train: -12.11521721, KL_z: 1.24780822, KL_s: 0.03155565, reconstruction loss: -10.83585334\n",
      "Epoch: [200]  time: 1.4572, ELBO_train: -11.68682480, KL_z: 1.32029927, KL_s: 0.01734877, reconstruction loss: -10.34917676\n",
      "Epoch: [300]  time: 2.1342, ELBO_train: -11.76412106, KL_z: 1.42126477, KL_s: 0.01514816, reconstruction loss: -10.32770813\n",
      "Epoch: [400]  time: 2.8198, ELBO_train: -11.64529896, KL_z: 1.40081096, KL_s: 0.01474285, reconstruction loss: -10.22974515\n",
      "Epoch: [500]  time: 3.4625, ELBO_train: -11.63064003, KL_z: 1.52212512, KL_s: 0.01466656, reconstruction loss: -10.09384835\n",
      "Epoch: [600]  time: 4.1046, ELBO_train: -11.55868340, KL_z: 1.56701541, KL_s: 0.01482153, reconstruction loss: -9.97684646\n",
      "Epoch: [700]  time: 4.7618, ELBO_train: -11.33791542, KL_z: 1.62374008, KL_s: 0.01600027, reconstruction loss: -9.69817507\n",
      "Epoch: [800]  time: 5.4296, ELBO_train: -11.67842293, KL_z: 1.69686770, KL_s: 0.01516533, reconstruction loss: -9.96638989\n",
      "Early stopping at epoch 800.\n",
      "Training finished.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'HI-VAE_weibull'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/hivae/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HI-VAE_weibull'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     list_df_gen_control\u001b[38;5;241m.\u001b[39mappend(df_gen_control)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# df_gen_control_dict[generator_name] = list_df_gen_control\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mdf_gen_control\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerator_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(list_df_gen_control)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hivae/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hivae/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HI-VAE_weibull'"
     ]
    }
   ],
   "source": [
    "for i in range(n_simulated_dataset):\n",
    "\n",
    "    seed = i\n",
    "\n",
    "    control, treated, types = simulation(treatment_effect, n_samples, independent, feature_types_list,\n",
    "                                        n_features_bytype, n_active_features, p_treated, shape_T,\n",
    "                                        shape_C, scale_C, scale_C_indep, data_types_create, seed=seed)\n",
    "    control = control.drop(columns='treatment')\n",
    "\n",
    "    data_file_control = os.path.join(f\"./dataset/{dataset_name}\", \"data_control.csv\")\n",
    "    feat_types_file_control = os.path.join(f\"./dataset/{dataset_name}\", \"data_types_control.csv\")\n",
    "    control.to_csv(data_file_control, index=False, header=False)\n",
    "    types.to_csv(feat_types_file_control, index=False)\n",
    "\n",
    "    # Load and process control data\n",
    "    df_init_control_encoded, feat_types_dict, miss_mask_control, true_miss_mask_control, _ = data_processing.read_data(\n",
    "            data_file_control, feat_types_file_control, miss_file=\"Missing.csv\", true_miss_file=None)\n",
    "    data_init_control_encoded = torch.from_numpy(df_init_control_encoded.values)\n",
    "    data_init_control = data_processing.discrete_variables_transformation(data_init_control_encoded, feat_types_dict)\n",
    "\n",
    "    # Format control data into DataFrame\n",
    "    fnames = types['name'][:-1].tolist() + [\"time\", \"censor\"]\n",
    "    df_init_control = pd.DataFrame(data_init_control.numpy(), columns=fnames)\n",
    "    df_init_control[\"treatment\"] = 0\n",
    "\n",
    "    # df_gen_control_dict ={}\n",
    "    # For each generator, perform the data generation with the best params\n",
    "    for generator_name in generators_sel:\n",
    "        best_params = best_params_dict[generator_name]\n",
    "        if generator_name in [\"HI-VAE_lognormal\", \"HI-VAE_weibull\", \"HI-VAE_piecewise\", \"HI-VAE_weibull_prior\", \"HI-VAE_piecewise_prior\"]:\n",
    "            if generator_name in [\"HI-VAE_weibull_prior\", \"HI-VAE_piecewise_prior\"]:\n",
    "                gen_from_prior = True\n",
    "            else:\n",
    "                gen_from_prior = False\n",
    "            feat_types_dict_ext = adjust_feat_types_for_generator(generator_name, feat_types_dict)\n",
    "            data_gen_control, s_total, z_total, y_total = generators_dict[generator_name].run(df_init_control_encoded, miss_mask_control, \n",
    "                                                                    true_miss_mask_control, feat_types_dict_ext, \n",
    "                                                                    n_generated_dataset, params=best_params, epochs=10000, gen_from_prior=gen_from_prior, return_latent_vectors=True)\n",
    "        # else:\n",
    "        #     data_gen_control = generators_dict[generator_name].run(data_init_control, columns=fnames, \n",
    "        #                                                             target_column=\"censor\", time_to_event_column=\"time\", \n",
    "        #                                                             n_generated_dataset=n_generated_dataset, \n",
    "        #                                                             params=best_params)\n",
    "\n",
    "        latent_s[generator_name].append(s_total)\n",
    "        latent_z[generator_name].append(z_total)\n",
    "        latent_y[generator_name].append(y_total)\n",
    "\n",
    "        list_df_gen_control = []\n",
    "        for i in range(n_generated_dataset):\n",
    "            df_gen_control = pd.DataFrame(data_gen_control[i].numpy(), columns=fnames)\n",
    "            df_gen_control[\"treatment\"] = 0\n",
    "            list_df_gen_control.append(df_gen_control)\n",
    "        # df_gen_control_dict[generator_name] = list_df_gen_control\n",
    "\n",
    "        df_gen_control_dict[generator_name].append(list_df_gen_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "225cf601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 150]) torch.Size([300, 60]) torch.Size([300, 2275])\n"
     ]
    }
   ],
   "source": [
    "print(s_total.shape, z_total.shape, y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35d3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hivae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
