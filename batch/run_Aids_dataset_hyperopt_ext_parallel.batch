#!/bin/bash
#SBATCH --job-name=Aids_hyperopt_ext    # A name for your job
#SBATCH --cpus-per-gpu=16               # Set number of CPUs per GPU card (adjust if needed)
#SBATCH --partition=gpu                 # Use the GPU partition
#SBATCH --gres=gpu:v100:1               # Request 1 A100 GPU
#SBATCH --mem=24G                       # Memory allocation, adjust based on your usage
#SBATCH --time=2-00:00:00               # Adjust the time limit as needed (10 hours here)
#SBATCH --array=0-5                     # one task per method
#SBATCH --output=logs/aids_ext_%A_%a.out     # Output file named after job and ID
#SBATCH --error=logs/aids_ext_%A_%a.err

echo "### Starting GPU job: $SLURM_JOB_NAME ###"
cd ${SLURM_SUBMIT_DIR}

module purge

# Load your Python environment
source /home/$USER/.bashrc
source activate .venv_HI_VAE_ext

# Arguments
method_ID=${SLURM_ARRAY_TASK_ID}

# Run your Python script
python3 Aids_hyperopt_train_full_ext_parallel.py $method_ID
